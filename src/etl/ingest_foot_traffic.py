# etl/ingest_foot_traffic.py
import os
import random
import requests
import numpy as np
from datetime import datetime, timedelta
from etl.utils import safe_request, get_db_conn, logging

FOOT_KEY = os.getenv("FOOT_TRAFFIC_API_KEY")


def fetch_foot_traffic(venue_external_id, venue_type=None):
    """
    Fetch foot traffic data for a venue using BestTime API

    Args:
        venue_external_id (str): External venue identifier (Google Place ID)
        venue_type (str): Type of venue for fallback data generation

    Returns:
        dict: Foot traffic data or None if no API key available
    """
    if not FOOT_KEY:
        logging.error(
            "FOOT_TRAFFIC_API_KEY not set - cannot fetch real foot traffic data"
        )
        return None

    try:
        # BestTime API endpoint for venue analysis
        url = "https://besttime.app/api/v1/forecasts"
        headers = {
            "Authorization": f"ApiKey {FOOT_KEY}",
            "Content-Type": "application/json",
        }

        # BestTime API expects venue_id (Google Place ID) and venue_name
        # Let's try a simpler payload format
        payload = {
            "venue_id": venue_external_id,
        }

        logging.info(f"Fetching real foot traffic data for venue {venue_external_id}")
        response = requests.post(url, json=payload, headers=headers, timeout=30)

        # If we get a 400 error, let's try the GET endpoint instead
        if response.status_code == 400:
            logging.info("POST request failed, trying GET endpoint...")
            get_url = f"https://besttime.app/api/v1/forecasts/{venue_external_id}"
            response = requests.get(get_url, headers=headers, timeout=30)

        response.raise_for_status()
        api_data = response.json()

        # Convert BestTime API response to our internal format
        return convert_besttime_to_internal_format(
            api_data, venue_external_id, venue_type
        )

    except requests.exceptions.RequestException as e:
        logging.error(f"Failed to fetch foot traffic data for {venue_external_id}: {e}")
        # Instead of raising, return None to indicate no data available
        # This prevents fallback to synthetic data
        return None
    except Exception as e:
        logging.error(
            f"Error processing foot traffic data for {venue_external_id}: {e}"
        )
        return None


def convert_besttime_to_internal_format(besttime_data, venue_external_id, venue_type):
    """
    Convert BestTime API response to our internal format

    Args:
        besttime_data (dict): Raw BestTime API response
        venue_external_id (str): Venue identifier
        venue_type (str): Type of venue

    Returns:
        dict: Data in our internal format
    """
    current_time = datetime.utcnow()
    traffic_data = []

    try:
        # BestTime API returns analysis data with busy hours
        analysis = besttime_data.get("analysis", {})
        busy_hours = analysis.get("busy_hours", [])

        if not busy_hours:
            logging.warning(f"No busy hours data found for venue {venue_external_id}")
            return None

        # Generate hourly data for the past 24 hours based on BestTime patterns
        for i in range(24):
            timestamp = current_time - timedelta(hours=i)
            hour = timestamp.hour

            # Find the corresponding busy hour data
            busy_hour_data = None
            for bh in busy_hours:
                if bh.get("hour") == hour:
                    busy_hour_data = bh
                    break

            if busy_hour_data:
                # Use real BestTime data
                busyness_score = busy_hour_data.get("busyness_score", 0)
                # Convert busyness score (0-100) to visitor count estimate
                base_visitors = max(1, int(busyness_score * 0.5))  # Scale appropriately

                traffic_entry = {
                    "timestamp": timestamp.isoformat(),
                    "visitors_count": base_visitors,
                    "median_dwell_seconds": busy_hour_data.get(
                        "dwell_time", 1800
                    ),  # Default 30 min
                    "visitors_change_24h": 0,  # BestTime doesn't provide this directly
                    "visitors_change_7d": 0,  # BestTime doesn't provide this directly
                    "peak_hour_ratio": busyness_score / 100.0,
                    "confidence_score": 0.9,  # High confidence for real API data
                }
            else:
                # Fill in missing hours with minimal data
                traffic_entry = {
                    "timestamp": timestamp.isoformat(),
                    "visitors_count": 1,
                    "median_dwell_seconds": 1800,
                    "visitors_change_24h": 0,
                    "visitors_change_7d": 0,
                    "peak_hour_ratio": 0.1,
                    "confidence_score": 0.5,
                }

            traffic_data.append(traffic_entry)

        return {
            "venue_id": venue_external_id,
            "data_source": "besttime_api",
            "generated_at": current_time.isoformat(),
            "traffic_data": traffic_data,
            "metadata": {
                "venue_type": venue_type or "unknown",
                "data_points": len(traffic_data),
                "time_range_hours": 24,
                "api_provider": "BestTime",
            },
        }

    except Exception as e:
        logging.error(
            f"Error converting BestTime data for venue {venue_external_id}: {e}"
        )
        return None


def process_foot_traffic_data(raw_data):
    """
    Process raw foot traffic data into standardized format

    Args:
        raw_data (dict): Raw foot traffic response

    Returns:
        list: Processed traffic records
    """
    if not raw_data or "traffic_data" not in raw_data:
        return []

    processed_records = []
    venue_id = raw_data.get("venue_id")

    for entry in raw_data["traffic_data"]:
        processed_record = {
            "venue_external_id": venue_id,
            "ts": entry["timestamp"],
            "visitors_count": entry["visitors_count"],
            "median_dwell_seconds": entry["median_dwell_seconds"],
            "visitors_change_24h": entry.get("visitors_change_24h", 0),
            "visitors_change_7d": entry.get("visitors_change_7d", 0),
            "peak_hour_ratio": entry.get("peak_hour_ratio", 1.0),
            "source": raw_data.get("data_source", "unknown"),
            "confidence_score": entry.get("confidence_score", 0.8),
        }
        processed_records.append(processed_record)

    return processed_records


def upsert_venue_traffic(venue_id, ts, visitors_count, dwell, **kwargs):
    """
    Insert or update venue traffic data in database

    Args:
        venue_id (str): Venue ID
        ts (str/datetime): Timestamp
        visitors_count (int): Number of visitors
        dwell (int): Median dwell time in seconds
        **kwargs: Additional fields like visitors_change_24h, etc.
    """
    conn = get_db_conn()
    cur = conn.cursor()

    try:
        # Convert datetime to string if needed
        if isinstance(ts, datetime):
            ts = ts.isoformat()

        cur.execute(
            """
            INSERT INTO venue_traffic (
                venue_id, ts, visitors_count, median_dwell_seconds, 
                visitors_change_24h, visitors_change_7d, peak_hour_ratio, source
            )
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT (venue_id, ts) DO UPDATE SET
                visitors_count = EXCLUDED.visitors_count,
                median_dwell_seconds = EXCLUDED.median_dwell_seconds,
                visitors_change_24h = EXCLUDED.visitors_change_24h,
                visitors_change_7d = EXCLUDED.visitors_change_7d,
                peak_hour_ratio = EXCLUDED.peak_hour_ratio,
                source = EXCLUDED.source,
                updated_at = CURRENT_TIMESTAMP
            """,
            (
                venue_id,
                ts,
                visitors_count,
                dwell,
                kwargs.get("visitors_change_24h", 0),
                kwargs.get("visitors_change_7d", 0),
                kwargs.get("peak_hour_ratio", 1.0),
                kwargs.get("source", "foottraffic"),
            ),
        )

        conn.commit()
        logging.info(f"Successfully upserted traffic data for venue {venue_id} at {ts}")

    except Exception as e:
        conn.rollback()
        logging.error(f"Error upserting venue traffic data: {e}")
        raise
    finally:
        cur.close()
        conn.close()


def bulk_upsert_venue_traffic(traffic_records):
    """
    Bulk insert/update multiple traffic records

    Args:
        traffic_records (list): List of traffic record dictionaries
    """
    if not traffic_records:
        return

    conn = get_db_conn()
    cur = conn.cursor()

    try:
        for record in traffic_records:
            upsert_venue_traffic(
                venue_id=record["venue_external_id"],
                ts=record["ts"],
                visitors_count=record["visitors_count"],
                dwell=record["median_dwell_seconds"],
                visitors_change_24h=record.get("visitors_change_24h", 0),
                visitors_change_7d=record.get("visitors_change_7d", 0),
                peak_hour_ratio=record.get("peak_hour_ratio", 1.0),
                source=record.get("source", "foottraffic"),
            )

        logging.info(
            f"Successfully bulk upserted {len(traffic_records)} traffic records"
        )

    except Exception as e:
        logging.error(f"Error in bulk upsert: {e}")
        raise


def fetch_and_store_foot_traffic_for_venues(venue_list):
    """
    Fetch and store foot traffic data for multiple venues

    Args:
        venue_list (list): List of venue dictionaries with 'external_id' and 'category'

    Returns:
        dict: Summary of processing results
    """
    results = {"processed_venues": 0, "total_records": 0, "errors": []}

    for venue in venue_list:
        try:
            venue_id = venue.get("external_id")
            venue_type = venue.get("category", "").lower()

            # Map venue categories to our internal types
            category_mapping = {
                "restaurant": "restaurant",
                "food": "restaurant",
                "store": "retail",
                "shopping": "retail",
                "bar": "bar",
                "nightlife": "bar",
                "cafe": "coffee",
                "coffee": "coffee",
                "gym": "gym",
                "fitness": "gym",
            }

            mapped_type = None
            for key, value in category_mapping.items():
                if key in venue_type:
                    mapped_type = value
                    break

            # Fetch traffic data
            raw_data = fetch_foot_traffic(venue_id, mapped_type)

            if raw_data:
                # Process and store data
                processed_records = process_foot_traffic_data(raw_data)
                if processed_records:
                    bulk_upsert_venue_traffic(processed_records)
                    results["total_records"] += len(processed_records)

                results["processed_venues"] += 1

        except Exception as e:
            error_msg = (
                f"Error processing venue {venue.get('external_id', 'unknown')}: {e}"
            )
            results["errors"].append(error_msg)
            logging.error(error_msg)

    return results


# Main execution for testing
if __name__ == "__main__":
    # Test the foot traffic generation
    print("Testing foot traffic data generation...")

    test_venues = [
        {"external_id": "test_restaurant_1", "category": "restaurant"},
        {"external_id": "test_retail_1", "category": "store"},
        {"external_id": "test_bar_1", "category": "bar"},
    ]

    for venue in test_venues:
        print(f"\nTesting {venue['external_id']} ({venue['category']})...")

        # Generate sample data
        raw_data = fetch_foot_traffic(venue["external_id"], venue["category"])

        if raw_data and "traffic_data" in raw_data:
            print(f"Generated {len(raw_data['traffic_data'])} traffic records")

            # Show sample record
            sample = raw_data["traffic_data"][0]
            print(
                f"Sample: {sample['visitors_count']} visitors, {sample['median_dwell_seconds']}s dwell time"
            )

            # Process data
            processed = process_foot_traffic_data(raw_data)
            print(f"Processed {len(processed)} records for database storage")
        else:
            print("No data generated")
